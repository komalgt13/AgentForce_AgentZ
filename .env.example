# Open Source LLM Configuration
# Options: ollama, huggingface, llamacpp
LLM_PROVIDER=huggingface
LLM_MODEL=microsoft/DialoGPT-small

# Alternative models (uncomment to use)
# LLM_MODEL=llama3.2:3b
# LLM_MODEL=mistral:7b

# Ollama Configuration (if using Ollama provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# HuggingFace Configuration (optional)
HUGGINGFACE_API_TOKEN=optional_token_here
HUGGINGFACE_MODEL=microsoft/DialoGPT-small

# Local Model Configuration
LOCAL_MODEL_PATH=./models/
USE_GPU=true
MODEL_QUANTIZATION=4bit

# Embedding Model (Open Source)
EMBEDDING_PROVIDER=huggingface  # Options: huggingface, ollama
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Application Settings
MAX_PERSONAS=8
MIN_PERSONAS=2
DEFAULT_PERSONAS=4

# Performance Settings
MAX_TOKENS=2048
TEMPERATURE=0.3
TOP_P=0.9
BATCH_SIZE=4

# Debug Settings
DEBUG=false
VERBOSE_LOGGING=false
